{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script Assignment 4 - \n",
    "## Zach Novak, Marco Bogani, Ivan Lima, Daman Sawhney and Sulaiman Karmali. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame head preview...\n",
      "     income    age  Credit_Score  dtir1  loan_amount  Status\n",
      "0   1740.0  25-34           758   45.0       116500       1\n",
      "1   4980.0  55-64           552    NaN       206500       1\n",
      "2   9480.0  35-44           834   46.0       406500       0\n",
      "3  11880.0  45-54           587   42.0       456500       0\n",
      "4  10440.0  25-34           602   39.0       696500       0\n",
      "\n",
      "Data types before processing...\n",
      " income          float64\n",
      "age              object\n",
      "Credit_Score      int64\n",
      "dtir1           float64\n",
      "loan_amount       int64\n",
      "Status            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Read CSV into a DataFrame\n",
    "df = pd.read_csv(r'C:\\Users\\Setup User\\University of Central Florida\\CAP5619_GRP - General\\Script Assigments\\Script_Assign_2\\LoanData.csv')\n",
    "\n",
    "# Selecting the relevant columns\n",
    "df = df.loc[:, ['income', 'age', 'Credit_Score', 'dtir1', 'loan_amount','Status']]\n",
    "\n",
    "# df preview\n",
    "print(\"\\nDataFrame head preview...\\n\",df.head())\n",
    "\n",
    "# data types before processing\n",
    "print(\"\\nData types before processing...\\n\",df.dtypes)\n",
    "\n",
    "# Remove NA values\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "# before data type can be converted to int, we need to fill in the missing values\n",
    "df['income'] = df['income'].astype(int)\n",
    "df['Credit_Score'] = df['Credit_Score'].astype(int)\n",
    "df['dtir1'] = df['dtir1'].astype(int)\n",
    "df['loan_amount'] = df['loan_amount'].astype(int)\n",
    "df['Status'] = df['Status'].astype(int)\n",
    "df['age'] = df['age'].astype(str)\n",
    "\n",
    "# Function to reformat age column\n",
    "def process_age_range(value):\n",
    "    if '-' in value:\n",
    "        age_range = value.split('-')\n",
    "        return age_range[1]\n",
    "    elif value.startswith('>'):\n",
    "        return value[1:]\n",
    "    elif value.startswith('<'):\n",
    "        return value[1:]\n",
    "    else:\n",
    "        return value\n",
    "df['age'] = df['age'].apply(process_age_range)\n",
    "\n",
    "# Set age to int data type\n",
    "df['age'] = df['age'].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "df_with_nan = df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Above, it can be observed that the columns chosen for this study are different data types (float64, object, int64). Code is implemented to convert all columns to an integer type as required by the Gradient Descent. For the age column, first the Process_age_function is defined to remove the value range format as seen in the DataFrame head preview per the above cell's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types post processing...\n",
      " income          int32\n",
      "age             int32\n",
      "Credit_Score    int32\n",
      "dtir1           int32\n",
      "loan_amount     int32\n",
      "Status          int32\n",
      "dtype: object\n",
      "\n",
      "DataFrame head preview...\n",
      "    income  age  Credit_Score  dtir1  loan_amount  Status\n",
      "0    1740   34           758     45       116500       1\n",
      "2    9480   44           834     46       406500       0\n",
      "3   11880   54           587     42       456500       0\n",
      "\n",
      "DataFrame tail preview...\n",
      "         income  age  Credit_Score  dtir1  loan_amount  Status\n",
      "148667    6900   54           702     49       446500       0\n",
      "148668    7140   64           737     29       196500       0\n",
      "148669    7260   54           830     44       406500       0\n",
      "\n",
      "DataFrame description...\n",
      "           income        age  Credit_Score      dtir1  loan_amount     Status\n",
      "count  124439.00  124439.00     124439.00  124439.00    124439.00  124439.00\n",
      "mean     7013.19      54.85        699.80      37.74    328865.90       0.16\n",
      "std      6508.56      13.26        115.83      10.54    182287.52       0.37\n",
      "min         0.00      25.00        500.00       5.00     16500.00       0.00\n",
      "25%      3780.00      44.00        600.00      31.00    196500.00       0.00\n",
      "50%      5760.00      54.00        699.00      39.00    296500.00       0.00\n",
      "75%      8580.00      64.00        800.00      45.00    436500.00       0.00\n",
      "max    578580.00      74.00        900.00      61.00   3576500.00       1.00\n"
     ]
    }
   ],
   "source": [
    "# DataFrame after preprocessing\n",
    "\n",
    "print(\"\\nData types post processing...\\n\",df.dtypes)\n",
    "print(\"\\nDataFrame head preview...\\n\",df.head(3))\n",
    "print(\"\\nDataFrame tail preview...\\n\",df.tail(3))\n",
    "print(\"\\nDataFrame description...\\n\",df.describe().round(2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The outcome of the preprocessing can be viewed in the above cell's output. All columns are now an integer data type, the DataFrame head preview shows the data is formatted, and the DataFrame description is able to now give meaningful analysis for the dataset. However, there is one item of concern. The min values for income is 0 which signifies incomplete data for those rows in the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame description...\n",
      "           income        age  Credit_Score      dtir1  loan_amount     Status\n",
      "count  124091.00  124091.00     124091.00  124091.00    124091.00  124091.00\n",
      "mean     7032.86      54.85        699.80      37.81    328905.25       0.16\n",
      "std      6507.06      13.26        115.83      10.47    182183.98       0.37\n",
      "min        60.00      25.00        500.00       5.00     16500.00       0.00\n",
      "25%      3780.00      44.00        600.00      31.00    196500.00       0.00\n",
      "50%      5820.00      54.00        699.00      39.00    296500.00       0.00\n",
      "75%      8580.00      64.00        800.00      45.00    436500.00       0.00\n",
      "max    578580.00      74.00        900.00      61.00   3576500.00       1.00\n",
      "\n",
      "\n",
      "DataFrame WITH NaN values row count...\n",
      " 124439\n",
      "\n",
      "DataFrame WITHOUT NaN values row count...\n",
      " 124091\n"
     ]
    }
   ],
   "source": [
    "# set columns to replace 0 values to NaN, then have the NaN values removed\n",
    "df['income'] = df['income'].replace(0, np.nan)\n",
    "\n",
    "# remove NaN values from the DataFrame\n",
    "df = df.dropna()\n",
    "\n",
    "# DataFrame statistics after removing NaN values\n",
    "print(\"\\nDataFrame description...\\n\",df.describe().round(2))\n",
    "\n",
    "\n",
    "print(\"\\n\\nDataFrame WITH NaN values row count...\\n\", len(df_with_nan))\n",
    "print(\"\\nDataFrame WITHOUT NaN values row count...\\n\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With the 0 and NaN values removed, the dataset description shows a more meaningful statistical overview. \n",
    "* It can be confirmed by the before and after DataFrame len() change. \n",
    "\n",
    "### Splitting training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for training\n",
    "X = df[['income', 'age', 'Credit_Score', 'dtir1', 'loan_amount']].values\n",
    "y = df['Status'].values  # Assuming the target variable column is 'Status'\n",
    "\n",
    "# Split the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling and cost computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "vc = VotingClassifier(estimators=[('rf', rf), ('gb', gb)], voting='soft')\n",
    "\n",
    "# Create a dictionary to hold models and their names\n",
    "models = {'Random Forest': rf, 'Gradient Boosting': gb, 'Voting Classifier': vc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test models\n",
    "\n",
    "This is done in a loop with each model being tested and it's performance metrics printed in the cell. The performance is measured for each model's Accuracy, Precision, Recall, F1 Score, and ROC-AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest model evaluated:\n",
      "Accuracy: 0.843265240340062, Precision: 0.5605911330049261, Recall: 0.14178918514826813, F1 Score: 0.22633253778838505, ROC-AUC: 0.6657093658337501\n",
      "\n",
      "Gradient Boosting model evaluated:\n",
      "Accuracy: 0.8459244933317217, Precision: 0.739240506329114, Recall: 0.07276351856466484, F1 Score: 0.132486388384755, ROC-AUC: 0.6947125173954618\n",
      "\n",
      "Voting Classifier model evaluated:\n",
      "Accuracy: 0.8467706192836134, Precision: 0.6581325301204819, Recall: 0.1088960877149265, F1 Score: 0.18687192644857814, ROC-AUC: 0.6864592230877833\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "    # Evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    # Store results\n",
    "    results[name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1, 'ROC-AUC': roc_auc}\n",
    "    print(f'\\n{name} model evaluated:')\n",
    "    print(f'Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1 Score: {f1}, ROC-AUC: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Model for Loan Default Prediction - Analysis\n",
    "\n",
    "The F1 score is used to determine the best model in the scenario of predicting loan default. This is because Recall is a key metric as well as precision, which is where F1 score is a score of the balance between a model's precision and recall. \n",
    "\n",
    "* Recall is important because it would mean the model is good at catching defaults. \n",
    "* Precision is important because it will mean the model will not deny customers loans due to falesly predicted flags of loan default (false positives).\n",
    "* F1 Score is important because it uses the harmonic mean in its calculation in contrast to the arithmetic mean. This will ensure F1 score is only high if both precision and recall are high. It is a good blend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best performing model: Random Forest\n",
      "\n",
      "**Performance metrics**\n",
      "Accuracy: 0.8433\n",
      "Precision: 0.5606\n",
      "Recall: 0.1418\n",
      "F1 Score: 0.2263\n",
      "ROC-AUC: 0.6657\n"
     ]
    }
   ],
   "source": [
    "# Compare models\n",
    "best_model = max(results, key=lambda k: results[k]['F1 Score'])\n",
    "print(f\"Best performing model: {best_model}\\n\")\n",
    "print(\"**Performance metrics**\")\n",
    "for metric, value in results[best_model].items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Insights:\n",
      "The **Random Forest** model has the best F1 Score, thus it is the best model for this scenario.\n"
     ]
    }
   ],
   "source": [
    "# Insights\n",
    "print(\"\\nInsights:\")\n",
    "print(\n",
    "    f\"The **{best_model}** model has the best F1 Score, thus it is the best model for this scenario.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
